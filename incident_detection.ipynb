{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9cd5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_67f188f703b48192b94b6990faccc75f0a866589bbd9fb30', created_at=1743882487.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_67f1890418708192b3812cd5416756110a866589bbd9fb30', content=[ResponseOutputText(annotations=[], text='{\"keywords\":[\"fire\",\"emergency\",\"accident\",\"evacuation\",\"panic\"],\"decision\":\"emergency\"}', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatTextJSONSchemaConfig(name='keywords', schema_={'type': 'object', 'strict': True, 'name': 'keywords', 'properties': {'keywords': {'type': 'array', 'items': {'type': 'string'}}, 'decision': {'type': 'string', 'enum': ['emergency', 'not emergency'], 'description': 'Decision on whether the image indicates an emergency or not.'}}, 'required': ['keywords', 'decision'], 'additionalProperties': False}, type='json_schema', description=None, strict=True)), truncation='disabled', usage=ResponseUsage(input_tokens=1177, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=24, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1201), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import base64\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "image_path = \"WhatsApp Image 2025-04-05 at 13.19.46_a48c2e13.jpeg\"\n",
    "base64_image = encode_image(image_path)\n",
    "json_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"keywords\": {\n",
    "            \"type\": \"array\",\n",
    "            \"description\": \"List of keywords that describe the content of the image.\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"minItems\": 5,\n",
    "            \"maxItems\": 5\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"keywords\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "prompt = (\n",
    "    \"I am sending an image of an incident. Find out whether the image indicates an emergency or not and \"\n",
    "    \"provide exactly five keywords describing the situation. Choose exclusively from keywords such as \"\n",
    "    \"'accident', 'not accident', 'emergency', 'fire', 'flood', etc. Return only a JSON object following \"\n",
    "    \"the schema provided.\"\n",
    ")\n",
    "\n",
    "client = openai.OpenAI(api_key=key)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"name\":\"keywords\",\n",
    "            \"type\": \"json_schema\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"strict\": True,\n",
    "                \"name\": \"keywords\",\n",
    "                \"properties\": {\n",
    "                    \"keywords\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"decision\":{\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"emergency\", \"not emergency\"],\n",
    "                        \"description\": \"Decision on whether the image indicates an emergency or not.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"keywords\",\"decision\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12f0e1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords': ['fire', 'emergency', 'accident', 'evacuation', 'panic'],\n",
       " 'decision': 'emergency'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.output_text) # Convert the response to JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f1efd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import openai\n",
    "import base64\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "key = os.getenv(\"OPEN_API_KEY\")\n",
    "openai.api_key = key\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "@app.route('/analyze', methods=['POST'])\n",
    "def analyze():\n",
    "    if 'image' not in request.files:\n",
    "        return jsonify({\"error\": \"No image provided\"}), 400\n",
    "\n",
    "    image_file = request.files['image']\n",
    "    base64_image = encode_image(image_file)\n",
    "\n",
    "    prompt = (\n",
    "        \"I am sending an image of an incident. Find out whether the image indicates an emergency or not and \"\n",
    "        \"provide exactly five keywords describing the situation. Choose exclusively from keywords such as \"\n",
    "        \"'accident', 'not accident', 'emergency', 'fire', 'flood', etc. Return only a JSON object following \"\n",
    "        \"the schema provided.\"\n",
    "    )\n",
    "    \n",
    "    client = openai.OpenAI(api_key=key)\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": prompt},\n",
    "                    {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        text={\n",
    "            \"format\": {\n",
    "                \"name\":\"keywords\",\n",
    "                \"type\": \"json_schema\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"strict\": True,\n",
    "                    \"name\": \"keywords\",\n",
    "                    \"properties\": {\n",
    "                        \"keywords\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"decision\":{\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"emergency\", \"not emergency\"],\n",
    "                            \"description\": \"Decision on whether the image indicates an emergency or not.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"keywords\",\"decision\"],\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = json.loads(response.output_text)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": \"Failed to parse response\", \"details\": str(e)}), 500\n",
    "    \n",
    "    if result.get(\"decision\") == \"emergency\":\n",
    "        payload = {\n",
    "            \"event\": \"emergency_detected\",\n",
    "            \"keywords\": result.get(\"keywords\", [])\n",
    "        }\n",
    "\n",
    "        return jsonify(payload), 200\n",
    "    else:\n",
    "        return jsonify({\"message\": \"No emergency detected\", \"keywords\": result.get(\"keywords\", [])}), 200\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
